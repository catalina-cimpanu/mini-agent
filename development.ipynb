{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3873df22",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6662de52",
   "metadata": {},
   "source": [
    "## Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e8ce8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anthropic API Key loaded: True\n",
      "Anthropic model: claude-sonnet-4-20250514\n",
      "OpenAI API Key loaded: True\n",
      "OpenAI model: gpt-4o-mini\n",
      "gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "ANTHROPIC_MODEL = os.getenv(\"ANTHROPIC_MODEL\")\n",
    "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\")\n",
    "\n",
    "# Verify keys are loaded\n",
    "print(f'Anthropic API Key loaded: {bool(os.getenv(\"ANTHROPIC_API_KEY\"))}\\nAnthropic model: {os.getenv(\"ANTHROPIC_MODEL\")}')\n",
    "print(f'OpenAI API Key loaded: {bool(os.getenv(\"OPENAI_API_KEY\"))}\\nOpenAI model: {os.getenv(\"OPENAI_MODEL\")}')\n",
    "print(OPENAI_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ed7300",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff0f02f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, TypedDict, Annotated\n",
    "from datetime import datetime\n",
    "import json\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, AnyMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, END, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import ToolNode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b1bad3",
   "metadata": {},
   "source": [
    "# Configure LLM\n",
    "&rarr; choose anthropic / openai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22753f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using OPENAI as LLM provider\n"
     ]
    }
   ],
   "source": [
    "def get_llm(provider: Literal[\"anthropic\", \"openai\"] = \"openai\"):\n",
    "    \"\"\"Get LLM instance based on provider choice\"\"\"\n",
    "    if provider == \"anthropic\":\n",
    "        base_llm = ChatAnthropic(\n",
    "            model=ANTHROPIC_MODEL,\n",
    "            temperature=0.7,\n",
    "            max_tokens=1024\n",
    "        )\n",
    "    elif provider == \"openai\":\n",
    "        base_llm = ChatOpenAI(\n",
    "            model=OPENAI_MODEL,\n",
    "            temperature=0.7,\n",
    "            max_tokens=1024\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown provider: {provider}\")\n",
    "    \n",
    "    return base_llm\n",
    "\n",
    "\n",
    "# Choose your provider here\n",
    "LLM_PROVIDER = \"openai\"  # Change to \"anthropic\" if you prefer\n",
    "llm = get_llm(LLM_PROVIDER)\n",
    "\n",
    "print(f\"Using {LLM_PROVIDER.upper()} as LLM provider\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50155f77",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125242ad",
   "metadata": {},
   "source": [
    "## Create tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b0ce38",
   "metadata": {},
   "source": [
    "### get_current_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3ecf59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the datetime tool\n",
    "@tool\n",
    "def get_current_datetime() -> str:\n",
    "    \"\"\"Get the current date and time. Use this when you need to know today's date.\"\"\"\n",
    "    now = datetime.now()\n",
    "    return f\"Current date: {now.strftime('%Y-%m-%d')}, Current time: {now.strftime('%H:%M:%S')}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee392b2e",
   "metadata": {},
   "source": [
    "## Give access to tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df33902",
   "metadata": {},
   "source": [
    "### With bind_tools \n",
    "Possible but will be using the ToolBind option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68a6b0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools available: ['get_current_datetime']\n"
     ]
    }
   ],
   "source": [
    "# List of tools\n",
    "tools = [get_current_datetime]\n",
    "print(f\"Tools available: {[t.name for t in tools]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "955270f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind tools to the LLM\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16970f23",
   "metadata": {},
   "source": [
    "### With ToolNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ooszkxej78h",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToolNode created with tools: ['get_current_datetime']\n"
     ]
    }
   ],
   "source": [
    "# Create ToolNode - handles tool execution automatically\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "print(f\"ToolNode created with tools: {[t.name for t in tools]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14041799",
   "metadata": {},
   "source": [
    "# States "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "jpeh7i961s",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State = the data that flows through the workflow\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]  # LangGraph handles message merging\n",
    "    name: str                       # Employee name\n",
    "    start_date: str                 # Start date\n",
    "    end_date: str                   # End date (optional)\n",
    "    work_hours: float               # Weekly work hours\n",
    "    salary: float                   # Salary\n",
    "    info_complete: bool             # All info collected?\n",
    "    human_decision: str             # \"approve\" or \"reject\"\n",
    "    is_update: bool                 # New entry or update existing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f54d09f",
   "metadata": {},
   "source": [
    "# Helper variables and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ee6812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt for the chatbot\n",
    "SYSTEM_PROMPT = \"\"\"You are Lola, a friendly HR assistant collecting employee information.\n",
    "\n",
    "You have access to tools:\n",
    "- get_current_datetime: Use this tool when you need to know today's date (e.g., if user says \"today\", \"next monday\", \"in two weeks\")\n",
    "\n",
    "You need to collect these fields (one at a time, conversationally):\n",
    "1. name - Employee's full name\n",
    "2. start_date - Employment start date (normalize to YYYY-MM-DD)\n",
    "3. end_date - Employment end date, can be empty if ongoing (normalize to YYYY-MM-DD or \"ongoing\")\n",
    "4. work_hours - Weekly work hours (as a number)\n",
    "5. salary - Annual salary in CHF (as a number)\n",
    "\n",
    "Important rules:\n",
    "- Be friendly and conversational\n",
    "- Ask for ONE piece of information at a time\n",
    "- When user mentions relative dates like \"today\", \"tomorrow\", \"next week\" - USE THE get_current_datetime TOOL first!\n",
    "- The user may answer in ANY date format or language (e.g. \"1st of April 2026\", \"1. April 2026\", German or English).\n",
    "- You must ALWAYS normalize dates to ISO format: YYYY-MM-DD.\n",
    "- If no end date exists, output null.\n",
    "- End date must always be after beginning date, without exception and no matter how sure the user say they are\n",
    "- Employee names must be properly capitalized: only the first letter of each word should be uppercase,\n",
    "  and the rest lowercase. Examples:\n",
    "  * \"Zacharias HAeusgen\" ‚Üí \"Zacharias Haeusgen\"\n",
    "  * \"john SMITH\" ‚Üí \"John Smith\"\n",
    "  * \"MARIA garcia\" ‚Üí \"Maria Garcia\"\n",
    "- Salary can be provided in any format (e.g., \"50k EUR a year\", \"40K USD a year\", \"30k CHF a year\"). \n",
    "- Salary MUST ALWAYS be a positive number\n",
    "- You must ALWAYS convert the salary to CHF (Swiss Francs) as an annual integer amount.\n",
    "- Use these approximate conversion rates: 1 EUR = 0.95 CHF, 1 USD = 0.88 CHF, 1 GBP = 1.12 CHF\n",
    "- work hours must always be positive. maximum work hours allowed is 50 hours. if the user insists it is more, mention that it is not legal. do not accept negative values or values larger than 50.\n",
    "- Ask follow-up questions only if information is missing or unclear.\n",
    "\n",
    "When you have ALL the information, respond with ONLY a JSON object:\n",
    "{\"name\": \"...\", \"start_date\": \"YYYY-MM-DD\", \"end_date\": \"YYYY-MM-DD or ongoing\", \"work_hours\": number, \"salary\": number, \"complete\": true}\n",
    "\n",
    "If information is still missing, just chat normally (no JSON).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b03df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keywords to exit the conversation\n",
    "EXIT_KEYWORDS = {\"exit\", \"bye\", \"quit\", \"stop\", \"cancel\", \"goodbye\", \"end\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7gkmj8901la",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO keep this programmatic data check? or leave just the LLM ?\n",
    "def validate_data(data: dict) -> list[str]:\n",
    "    \"\"\"Validate collected data. Returns list of error messages.\"\"\"\n",
    "    errors = []\n",
    "    \n",
    "    # 1. Minimum yearly salary 20000 CHF\n",
    "    salary = data.get(\"salary\", 0)\n",
    "    if salary < 20000:\n",
    "        errors.append(f\"Salary must be at least 20,000 CHF (got {salary})\")\n",
    "    \n",
    "    # 2. Start date must be after 2010\n",
    "    start_date = data.get(\"start_date\", \"\")\n",
    "    if start_date:\n",
    "        start_year = int(start_date.split(\"-\")[0])\n",
    "        if start_year <= 2010:\n",
    "            errors.append(f\"Start date must be after 2010 (got {start_date})\")\n",
    "    \n",
    "    # 3. End date must be after start date (if not ongoing)\n",
    "    end_date = data.get(\"end_date\", \"\")\n",
    "    if end_date and end_date.lower() != \"ongoing\" and start_date:\n",
    "        if end_date <= start_date:\n",
    "            errors.append(f\"End date ({end_date}) must be after start date ({start_date})\")\n",
    "    \n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576e3122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_json_from_text(text: str) -> dict | None:\n",
    "    \"\"\"Find and parse JSON object from text, even if surrounded by other content.\"\"\"\n",
    "    match = re.search(r'\\{[^{}]*\"complete\"\\s*:\\s*true[^{}]*\\}', text)\n",
    "    if match:\n",
    "        try:\n",
    "            return json.loads(match.group())\n",
    "        except json.JSONDecodeError:\n",
    "            return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ecb451",
   "metadata": {},
   "source": [
    "# Nodes\n",
    "NB: Chatbots are nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "szp77uhfcm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NODE 1: Chatbot with tool support\n",
    "\n",
    "def chatbot(state: State) -> dict:\n",
    "    \"\"\"Chatbot node - calls LLM with tools, may request tools or collect data.\"\"\"\n",
    "    \n",
    "    messages = state.get(\"messages\", [])\n",
    "    \n",
    "    # --- EXIT CHECK (check last human message) ---\n",
    "    for msg in reversed(messages):\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            if msg.content.lower().strip() in EXIT_KEYWORDS:\n",
    "                print(\"üëã Conversation ended by user.\")\n",
    "                return {\"info_complete\": True, \"human_decision\": \"cancel\"}\n",
    "            break\n",
    "    \n",
    "    # --- BUILD LLM MESSAGES ---\n",
    "    llm_messages = [SystemMessage(content=SYSTEM_PROMPT)] + messages\n",
    "    \n",
    "    # First message - greet user\n",
    "    if not messages:\n",
    "        llm_messages.append(HumanMessage(content=\"Hi, I need to enter employee information.\"))\n",
    "    \n",
    "    # --- CALL LLM WITH TOOLS ---\n",
    "    response = llm_with_tools.invoke(llm_messages)\n",
    "    \n",
    "    # --- CHECK IF LLM WANTS TO USE TOOLS ---\n",
    "    if response.tool_calls:\n",
    "        print(f\"üîß LLM requesting tool: {response.tool_calls[0]['name']}\")\n",
    "        return {\"messages\": [response]}  # Workflow routes to ToolNode\n",
    "    \n",
    "    # --- NO TOOL CALL - PROCESS RESPONSE ---\n",
    "    assistant_message = response.content\n",
    "    print(f\"ü§ñ Lola: {assistant_message}\")\n",
    "    \n",
    "    # --- CHECK FOR COMPLETE JSON ---\n",
    "    data = extract_json_from_text(assistant_message)\n",
    "    \n",
    "    if data and data.get(\"complete\"):\n",
    "        errors = validate_data(data)\n",
    "        \n",
    "        if errors:\n",
    "            error_msg = \"‚ö†Ô∏è Validation errors:\\n\" + \"\\n\".join(f\"  - {e}\" for e in errors)\n",
    "            print(error_msg)\n",
    "            \n",
    "            user_input = input(\"You: \")\n",
    "            \n",
    "            return {\n",
    "                \"messages\": [response, AIMessage(content=error_msg), HumanMessage(content=user_input)],\n",
    "                \"info_complete\": False,\n",
    "            }\n",
    "        \n",
    "        print(\"‚úÖ All information collected and validated!\")\n",
    "        return {\n",
    "            \"messages\": [response],\n",
    "            \"name\": data[\"name\"],\n",
    "            \"start_date\": data[\"start_date\"],\n",
    "            \"end_date\": data[\"end_date\"],\n",
    "            \"work_hours\": float(data[\"work_hours\"]),\n",
    "            \"salary\": float(data[\"salary\"]),\n",
    "            \"info_complete\": True,\n",
    "        }\n",
    "    \n",
    "    # --- CONTINUE CONVERSATION ---\n",
    "    user_input = input(\"You: \")\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [response, HumanMessage(content=user_input)],\n",
    "        \"info_complete\": False,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "t5u1yqqwql",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NODE 2: Human verification - asks for approval via input()\n",
    "def human_verification(state: State) -> dict:\n",
    "    \"\"\"Shows collected data and asks human to approve or reject.\"\"\"\n",
    "    \n",
    "    # all these variables can be accessed and be worked with\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"üìã PLEASE REVIEW THE DATA:\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"   Name:       {state.get('name')}\")\n",
    "    print(f\"   Start date: {state.get('start_date')}\")\n",
    "    print(f\"   End date:   {state.get('end_date')}\")\n",
    "    print(f\"   Work hours: {state.get('work_hours')}\")\n",
    "    print(f\"   Salary:     {state.get('salary')} CHF\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    decision = input(\"Type 'approve' or 'reject': \").lower().strip()\n",
    "    \n",
    "    if decision == \"approve\":\n",
    "        print(\"‚úÖ Approved!\")\n",
    "        return {\"human_decision\": \"approve\"}\n",
    "    else:\n",
    "        print(\"‚ùå Rejected - returning to chatbot for corrections\")\n",
    "        return {\"human_decision\": \"reject\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe8cc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NODE 3: Create new entry\n",
    "def create_entry(state: State) -> State:\n",
    "    \"\"\"Creates a new employee record\"\"\"\n",
    "    \n",
    "    # TODO: Add database insert logic here\n",
    "    print(f\"‚úÖ [create_entry] Will create new entry for: {state.get('name')}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iufgrrttyjl",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NODE 4: Update existing entry  \n",
    "def update_entry(state: State) -> State:\n",
    "    \"\"\"Updates an existing employee record\"\"\"\n",
    "    \n",
    "    # TODO: Add database update logic here\n",
    "    print(f\"‚úÖ [update_entry] Will update entry for: {state.get('name')}\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06157c79",
   "metadata": {},
   "source": [
    "# Routers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6k45aeydejj",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROUTER 1: After chatbot - check if tools needed, then continue\n",
    "def route_after_chatbot(state: State) -> str:\n",
    "    \"\"\"Routes based on: tool calls, cancellation, or info complete.\"\"\"\n",
    "    \n",
    "    # Check for cancel\n",
    "    if state.get(\"human_decision\") == \"cancel\":\n",
    "        return END\n",
    "    \n",
    "    # Check if last message has tool calls\n",
    "    messages = state.get(\"messages\", [])\n",
    "    if messages:\n",
    "        last_msg = messages[-1]\n",
    "        if hasattr(last_msg, \"tool_calls\") and last_msg.tool_calls:\n",
    "            return \"tools\"  # Route to ToolNode\n",
    "    \n",
    "    # Check if info complete\n",
    "    if state.get(\"info_complete\"):\n",
    "        return \"human_verification\"\n",
    "    \n",
    "    return \"chatbot\"  # Continue collecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k5962ks4t5m",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROUTER 2: After human verification - what did human decide?\n",
    "def route_after_verification(state: State) -> str:\n",
    "    decision = state.get(\"human_decision\")\n",
    "    \n",
    "    if decision == \"reject\":\n",
    "        return \"chatbot\"             # Rejected -> go back to fix\n",
    "    \n",
    "    if decision == \"approve\":\n",
    "        if state.get(\"is_update\"):\n",
    "            return \"update_entry\"    # Update existing\n",
    "        return \"create_entry\"        # Create new\n",
    "    \n",
    "    return \"chatbot\"                 # No decision -> go back"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5debf9aa",
   "metadata": {},
   "source": [
    "# Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5o5tc628ecg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the graph (with ToolNode)\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"chatbot\", chatbot)\n",
    "workflow.add_node(\"tools\", tool_node)                 # ToolNode handles tool execution\n",
    "workflow.add_node(\"human_verification\", human_verification)\n",
    "workflow.add_node(\"create_entry\", create_entry)\n",
    "workflow.add_node(\"update_entry\", update_entry)\n",
    "\n",
    "# Add edges\n",
    "workflow.add_edge(START, \"chatbot\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    route_after_chatbot,\n",
    "    [\"chatbot\", \"tools\", \"human_verification\", END]\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"tools\", \"chatbot\")                 # After tools, back to chatbot\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"human_verification\", \n",
    "    route_after_verification,\n",
    "    [\"chatbot\", \"create_entry\", \"update_entry\"]\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"create_entry\", END)\n",
    "workflow.add_edge(\"update_entry\", END)\n",
    "\n",
    "print(\"Workflow created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1170rng7x",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile workflow\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "print(\"Workflow compiled!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba0aebc",
   "metadata": {},
   "source": [
    "# Visualize graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7brgowpt4tm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the workflow\n",
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sua5efytmm",
   "metadata": {},
   "source": [
    "# Run the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gje77lfg7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run workflow (with tool support!)\n",
    "initial_state = {\n",
    "    \"messages\": [],\n",
    "    \"name\": \"\",\n",
    "    \"start_date\": \"\",\n",
    "    \"end_date\": \"\",\n",
    "    \"work_hours\": 0.0,\n",
    "    \"salary\": 0.0,\n",
    "    \"info_complete\": False,\n",
    "    \"human_decision\": \"\",\n",
    "    \"is_update\": False,\n",
    "}\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"test-1\"}}\n",
    "\n",
    "# Run - try saying \"start date is today\" to test the tool!\n",
    "for event in app.stream(initial_state, config):\n",
    "    pass\n",
    "\n",
    "print(\"\\nüèÅ Workflow complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bc64bc",
   "metadata": {},
   "source": [
    "To Do       \n",
    " - add the other variables\n",
    " - ensure that limits are correct and that the user can't input whatever (consider keeping the programmatic validation of data, not only the llm)\n",
    " - add tool for vurrency conversion with current values\n",
    " - add langsmith to see consumption"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mini-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
